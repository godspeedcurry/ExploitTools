# 爬站长工具的爬虫
# 依赖：
# pip3 install click requests
# 用法：
# python3 spider.py --domain geely.com
import requests,re,click,time,sys
@click.command()
@click.option("-d","--domain",default="geely.com",help="domain name")
def main(domain):
	for i in range(1,5):
		try:
			url = 'http://tool.chinaz.com/subdomain/?domain={}&page={}'.format(domain,i)			
			r = requests.get(url=url,timeout=10)
			res = re.findall('domain=(.*?\.{})'.format(domain),r.content.decode('utf-8'))
			if res == []:
				break
			else:
				print('\n'.join(res))
		except Exception as e:
			print(e)
			break

main()
